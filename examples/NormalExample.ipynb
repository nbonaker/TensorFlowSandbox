{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import autograd\n",
    "from autograd import numpy as anp\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "\n",
    "from normal_example_lib import \\\n",
    "    normal_lp_suff, normal_lp, flatten_par, fold_par, get_objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "4.031689876244987\n"
     ]
    }
   ],
   "source": [
    "dim = 3\n",
    "num_obs = 10000\n",
    "\n",
    "mu_true = np.arange(dim, dtype=np.float64)\n",
    "sd_true = 0.5\n",
    "tau_true = 1 / sd_true ** 2\n",
    "print(tau_true)\n",
    "\n",
    "x = np.random.normal(loc=mu_true, scale=sd_true, size=(num_obs, dim))\n",
    "xsum = np.sum(x, axis=0)\n",
    "x2sum = x.T @ x\n",
    "\n",
    "muhat = xsum / num_obs\n",
    "covhat = x2sum / num_obs - np.outer(muhat, muhat) \n",
    "tauhat = 1 / np.mean(np.diag(covhat))\n",
    "print(tauhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=5912.032874155855>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_lp_suff(\n",
    "    mu=mu_true,\n",
    "    mu2=np.outer(mu_true, mu_true),\n",
    "    tau=tau_true,\n",
    "    log_tau=np.log(tau_true),\n",
    "    xsum=xsum,\n",
    "    x2sum=x2sum,\n",
    "    num_obs=num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=5912.032874155855>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = { 'xsum': xsum, 'x2sum': x2sum, 'num_obs': num_obs}\n",
    "par = { 'mu': mu_true, 'tau': tau_true }\n",
    "normal_lp(par, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 tf.Tensor(4.0, shape=(), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=5912.032874155855>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_flat = flatten_par(par)\n",
    "par_fold = fold_par(par_flat)\n",
    "print(par['tau'], par_fold['tau'])\n",
    "normal_lp(par_fold, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5912032874155855\n",
      "-0.5912032874155855\n",
      "-0.5912032874155855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5912032874155855,\n",
       " array([ 0.0074571 ,  0.01279885, -0.00299633, -0.01176175]),\n",
       " array([[ 4.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          7.45710490e-03],\n",
       "        [ 0.00000000e+00,  4.00000000e+00,  0.00000000e+00,\n",
       "          1.27988451e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  4.00000000e+00,\n",
       "         -2.99633086e-03],\n",
       "        [ 7.45710490e-03,  1.27988451e-02, -2.99633086e-03,\n",
       "          1.48823825e+00]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_objective, normal_objective_grad, normal_objective_hessian = get_objectives(data)\n",
    "\n",
    "lp = normal_objective(par_flat)\n",
    "grad = normal_objective_grad(par_flat)\n",
    "hess = normal_objective_hessian(par_flat)\n",
    "\n",
    "lp, grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.098163552483872\n",
      "3.098163552483872\n",
      "3.098163552483872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.098163552483872,\n",
       " array([ 0.57358346, -1.28924584, -3.65494473,  2.79032299]),\n",
       " array([[ 2.21393829,  0.        ,  0.        ,  0.57358346],\n",
       "        [ 0.        ,  2.21393829,  0.        , -1.28924584],\n",
       "        [ 0.        ,  0.        ,  2.21393829, -3.65494473],\n",
       "        [ 0.57358346, -1.28924584, -3.65494473,  4.29032299]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_flat = np.random.random(dim  + 1)\n",
    "lp = normal_objective(tf.convert_to_tensor(par_flat))\n",
    "grad = normal_objective_grad(tf.convert_to_tensor(par_flat))\n",
    "hess = normal_objective_hessian(par_flat)\n",
    "\n",
    "lp, grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.870358017715933\n",
      "2.870358017715933\n",
      "2.870358017715933\n",
      "1.0765031660029623\n",
      "1.0765031660029623\n",
      "1.0765031660029623\n",
      "-0.28368787776332793\n",
      "-0.28368787776332793\n",
      "-0.28368787776332793\n",
      "-0.4984050723023785\n",
      "-0.4984050723023785\n",
      "-0.4984050723023785\n",
      "-0.588313243808569\n",
      "-0.588313243808569\n",
      "-0.588313243808569\n",
      "-0.5912732908021225\n",
      "-0.5912732908021225\n",
      "-0.5912732908021225\n",
      "-0.5912784182781725\n",
      "-0.5912784182781725\n",
      "-0.5912784182781725\n"
     ]
    }
   ],
   "source": [
    "opt_result = sp.optimize.minimize(\n",
    "    x0=np.zeros(dim + 1),\n",
    "    fun=normal_objective,\n",
    "    jac=normal_objective_grad,\n",
    "    hess=normal_objective_hessian,\n",
    "    method=\"trust-exact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5912784182781725\n",
      "-0.5912784182781725\n",
      "-0.5912784182781725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 6.98816700e-09, -3.73646715e-06, -7.49973020e-06,  5.11490014e-06]),\n",
       " array([[ 4.03170362e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          6.98816700e-09],\n",
       "        [ 0.00000000e+00,  4.03170362e+00,  0.00000000e+00,\n",
       "         -3.73646715e-06],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  4.03170362e+00,\n",
       "         -7.49973020e-06],\n",
       "        [ 6.98816700e-09, -3.73646715e-06, -7.49973020e-06,\n",
       "          1.50000511e+00]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp = normal_objective(opt_result.x)\n",
    "grad = normal_objective_grad(opt_result.x)\n",
    "hess = normal_objective_hessian(opt_result.x)\n",
    "grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.86427449e-03  9.96799362e-01  2.00074722e+00] [-1.86427623e-03  9.96800289e-01  2.00074908e+00]\n",
      "4.031703624015668 4.031689876244987 4.0\n"
     ]
    }
   ],
   "source": [
    "par_opt = fold_par(opt_result.x)\n",
    "print(par_opt['mu'].numpy(), muhat)\n",
    "print(par_opt['tau'].numpy(), tauhat, tau_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def normal_lp_fun(par_flat):\n",
    "    return -1 * normal_lp(fold_par(par_flat), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-5912.784182781725, shape=(), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-5912.784182781725>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(normal_lp_fun(opt_result.x))\n",
    "f = normal_lp_fun.get_concrete_function(opt_result.x)\n",
    "f(tf.convert_to_tensor(opt_result.x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
